#ä» Tushare è·å–é‡ç‚¹Aè‚¡æœ€è¿‘ä¸€å¹´æ—¥çº¿æ•°æ®å¹¶å­˜å‚¨ä¸º CSV æ–‡ä»¶
import tushare as ts
import pandas as pd
from pathlib import Path
from datetime import datetime,timedelta
from utils.config_loader import load_env # åŠ è½½ç¯å¢ƒå˜é‡
from utils.logger import get_logger # æ—¥å¿—è®°å½•
from .stock_universe import IMPORTANT_STOCKS #é‡ç‚¹Aè‚¡æ¸…å•


config = load_env() #ä» .envæ–‡ä»¶è¯»å– TUSHARE_TOKENå’Œ LOG_PATH
logger = get_logger(__name__, config["LOG_PATH"])#è‡ªåŠ¨è·å–å½“å‰æ¨¡å—çš„åç§°ï¼Œåˆ›å»ºä¸€ä¸ªä¸å½“å‰æ¨¡å—å…³è”çš„æ—¥å¿—è®°å½•å™¨

ts.set_token(config["TUSHARE_TOKEN"])
pro = ts.pro_api()#åˆ›å»ºä¸€ä¸ª Tushare çš„ API å¯¹è±¡


def fetch_daily_data(ts_codes=None):
    """
    ä»Tushareè·å–Aè‚¡æ—¥çº¿æ•°æ®
    """

    end_date = datetime.now().strftime("%Y%m%d")
    start_date = (datetime.now() - timedelta(days=365)).strftime("%Y%m%d")

    # ç¡®å®šè¦è·å–çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
    if ts_codes is None:
        # ä»IMPORTANT_STOCKSä¸­æå–æ‰€æœ‰è‚¡ç¥¨ä»£ç 
        ts_codes = [stock["ts_code"] for stock in IMPORTANT_STOCKS]
    elif isinstance(ts_codes, str):
        ts_codes = [ts_codes]
    
    # åˆ›å»ºæ•°æ®å­˜å‚¨ç›®å½•
    Path("data/raw").mkdir(parents=True, exist_ok=True)
    
    all_data = []  # å­˜å‚¨æ‰€æœ‰è·å–çš„æ•°æ®
    
    for idx, ts_code in enumerate(ts_codes, 1):
        try:

            logger.info(f"æ­£åœ¨è·å– {ts_code} æ•°æ® ({idx}/{len(ts_codes)})...")
            print(f"ğŸ”„ æ­£åœ¨è·å– {ts_code} æ•°æ® ({idx}/{len(ts_codes)})...")
            
            df = pro.daily(ts_code=ts_code, start_date=start_date, end_date=end_date)
            
            if df.empty:
                logger.warning(f"{ts_code} æœªè·å–åˆ°æ•°æ®")
                print(f"âš ï¸  {ts_code} æœªè·å–åˆ°æ•°æ®")
                continue
            
            all_data.append(df)
            
            logger.info(f"{ts_code} æ•°æ®ä¿å­˜æˆåŠŸï¼Œå…± {len(df)} è¡Œã€‚")
            print(f"âœ… {ts_code} æ•°æ®ä¿å­˜æˆåŠŸï¼Œå…± {len(df)} è¡Œã€‚")
            
        except Exception as e:
            logger.error(f"è·å– {ts_code} æ•°æ®å¤±è´¥: {e}")
            print(f"âŒ è·å– {ts_code} æ•°æ®å¤±è´¥: {e}")
    
    # åˆå¹¶æ‰€æœ‰æ•°æ®
    if all_data:
        combined_df = pd.concat(all_data, ignore_index=True)
        
        # ä¿å­˜åˆå¹¶åçš„æ•°æ®
        combined_path = f"data/raw/all_stocks_daily_{end_date}.csv"
        combined_df.to_csv(combined_path, index=False, encoding='utf-8-sig')
        
        logger.info(f"æ‰€æœ‰è‚¡ç¥¨æ•°æ®å·²åˆå¹¶ä¿å­˜ï¼Œå…± {len(combined_df)} è¡Œã€‚")
        print(f"ğŸ‰ æ‰€æœ‰è‚¡ç¥¨æ•°æ®å·²åˆå¹¶ä¿å­˜ï¼Œå…± {len(combined_df)} è¡Œã€‚")
        
        return combined_df
    else:
        logger.warning("æœªè·å–åˆ°ä»»ä½•æ•°æ®")
        return None


if __name__ == "__main__":
    # è·å–æ‰€æœ‰é‡è¦Aè‚¡æ•°æ®
    fetch_daily_data()
